{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as pltimport \n",
    "%matplotlib inline\n",
    "from timeit import default_timer as timer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "def create_cnn(width, height, depth, filters=(16, 32, 64)):\n",
    "    # First CONV layer\n",
    "    inputShape = (height, width, depth)\n",
    "    inputs = Input(shape=inputShape)\n",
    "    x = inputs\n",
    "    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)   \n",
    "    # 2nd CONV\n",
    "    x = Conv2D(64, (3, 3))(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)  \n",
    "    # 3rd CONV\n",
    "    x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # 4th CONV\n",
    "    x = Conv2D(64, (3, 3))(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    # 5th CONV\n",
    "    x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x) \n",
    "    # 6th CONV\n",
    "    x = Conv2D(128, (3, 3))(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.7)(x)                             #0.5\n",
    "    # Flatten and Output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.7)(x)                             #0.5\n",
    "    model = Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Audio Features: Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_csv('train.csv',dtype=str)\n",
    "trainAudioPath = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Auido Features: Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv('test.csv', dtype=str)\n",
    "testAudioPath = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Audio Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAudioFeatures = np.load('trainAudioFeature277.npy', allow_pickle=True)\n",
    "testAudioFeatures = np.load('testAudioFeature277.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAudioFeatures = np.array(trainAudioFeatures)\n",
    "testAudioFeatures = np.array(testAudioFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk \n",
    "scaler1 = sk.preprocessing.StandardScaler().fit(trainAudioFeatures)\n",
    "trainAudioFeatures = scaler1.transform(trainAudioFeatures)\n",
    "testAudioFeatures = scaler1.transform(testAudioFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils.np_utils import to_categorical\n",
    "# LABELS\n",
    "train_labels = traindf[\"Class\"]\n",
    "test_labels = testdf[\"Class\"]\n",
    "#labels = to_categorical(labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(train_labels)\n",
    "train_labels = le.transform(train_labels)\n",
    "test_labels = le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 9, 3, 5, 6, 0, 1, 4, 7, 2, 0, 7, 6, 6, 0, 9, 3, 7, 1, 5, 8,\n",
       "       7, 6, 5, 8, 2, 1, 4, 6, 4, 5, 8, 2, 9, 1, 3, 4, 4, 2, 2, 8, 2, 8,\n",
       "       3, 7, 7, 1, 7, 7, 2, 8, 5, 6, 6, 2, 7, 0, 8, 1, 5, 6, 5, 5, 5, 0,\n",
       "       6, 7, 3, 6, 2, 0, 9, 3, 8, 2, 0, 8, 6, 7, 5, 2, 5, 4, 0, 0, 1, 1,\n",
       "       9, 5, 9, 0, 4, 4, 3, 8, 7, 3, 4, 6, 5, 2, 6, 1, 9, 6, 3, 6, 4, 7,\n",
       "       5, 1, 1, 9, 2, 9, 9, 9, 2, 1, 8, 1, 2, 4, 2, 3, 3, 1, 6, 5, 9, 0,\n",
       "       7, 1, 0, 2, 4, 9, 7, 7, 9, 1, 8, 1, 4, 9, 0, 1, 2, 7, 3, 8, 2, 2,\n",
       "       3, 1, 0, 4, 1, 3, 7, 3, 1, 9, 8, 4, 8, 0, 3, 0, 3, 4, 4, 5, 5, 3,\n",
       "       4, 6, 2, 0, 5, 5, 6, 1, 8, 3, 3, 7, 8, 9, 9, 6, 7, 0, 8, 7, 1, 6,\n",
       "       0, 1, 6, 8, 0, 0, 8, 2, 6, 4, 4, 8, 9, 1, 2, 8, 3, 5, 3, 4, 7, 9,\n",
       "       0, 7, 4, 3, 4, 4, 8, 0, 5, 7, 8, 2, 4, 5, 7, 1, 7, 1, 9, 2, 2, 9,\n",
       "       2, 9, 5, 6, 8, 6, 3, 5, 3, 2, 5, 3, 9, 6, 7, 9, 9, 5, 0, 9, 1, 0,\n",
       "       6, 6, 7, 6, 0, 5, 0, 3, 8, 4, 4, 8, 4, 8, 0, 9])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training CNN (1-D Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading data...\n",
      "[INFO] processing data...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 277, 512)          1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 277, 512)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 141824)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 141824)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              145228800 \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 145,762,832\n",
      "Trainable params: 145,762,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(277, 1), filters=512, kernel_size=1)`\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import concatenate\n",
    "import numpy as np\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPool1D\n",
    "from keras import regularizers, optimizers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "print(\"[INFO] loading data...\")\n",
    "#features, images, labels = features, images, labels\n",
    "\n",
    "print(\"[INFO] processing data...\")\n",
    "#split = train_test_split(features, images, labels, test_size=0.25, random_state=42)\n",
    "#(trainFeatureX, testFeatureX, trainImagesX, testImagesX, trainY, testY) = split\n",
    "\n",
    "\n",
    "trainFeatureX, testFeatureX, trainY, testY = trainAudioFeatures, testAudioFeatures, train_labels, test_labels\n",
    "\n",
    "# For prediction and Confusion Matrix\n",
    "trueY = testY\n",
    "\n",
    "trainY = to_categorical(trainY, 16)\n",
    "testY = to_categorical(testY, 16)\n",
    "\n",
    "\n",
    "# define model\n",
    "n_steps = 1\n",
    "n_features = 277\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(filters=64, kernel_size=1, activation='relu', input_shape=(n_steps, n_features)))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(50, activation='relu'))\n",
    "# model.add(Dense(16,activation=\"softmax\"))\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(nb_filter=512, filter_length=1, input_shape=(n_features, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# # create the MLP and CNN models\n",
    "# #mlp = create_mlp()\n",
    "# cnn = create_cnn(120, 1, 1)\n",
    "\n",
    "# # create the input to our final set of layers as the *output* of both the MLP and CNN\n",
    "# #combinedInput = concatenate([mlp.output, cnn.output])\n",
    "\n",
    "# Input = cnn.output\n",
    "\n",
    "# # The final FC layer head will have two dense layers, the final one being softmax layer\n",
    "# x = Dense(512, activation=\"relu\")(Input)\n",
    "# x = Dense(16, activation=\"softmax\")(x)\n",
    "\n",
    "# # The final model will accept audio on the MLP input and SPEC on the CNN input, outputting prediction\n",
    "# model_cnn = Model(inputs=cnn.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 77560 into shape (480,277,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-56781317c1ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[INFO] training model...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainFeatureX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m480\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m277\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestFeatureX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m277\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 77560 into shape (480,277,1)"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizers.rmsprop(lr=0.0005, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"]) #lr 0.0005\n",
    "\n",
    "# Train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(trainFeatureX.reshape(480, 277,1), trainY, validation_data=(testFeatureX.reshape(120, 277,1), testY), epochs=250, batch_size=32)  # 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "print(\"[INFO] Evaluating...\")\n",
    "model.evaluate(testFeatureX.reshape(120,277,1), testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
