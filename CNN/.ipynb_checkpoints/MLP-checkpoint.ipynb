{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as pltimport \n",
    "%matplotlib inline\n",
    "from timeit import default_timer as timer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Making CSV Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(csvName, dataDir):\n",
    "    with open(csvName,\"w\") as file:\n",
    "        file.write(\"ID,Class\\n\")\n",
    "        for fn in dataDir:\n",
    "            fileID  = fn.split('-')[-1].split('')[0]\n",
    "            classID = fileID.split('.')[-1]\n",
    "            file.write(str(fileID)+','+classID)\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Making .csv files #############\n",
    "\n",
    "#train_dir = np.array(glob(\"train/*\"))\n",
    "#write_to_csv(\"train.csv\",train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Making .csv files #############\n",
    "\n",
    "#test_dir = np.array(glob(\"test/*\"))\n",
    "#write_to_csv(\"test.csv\",test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Feature extraction & Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  24.8991486\n",
      "end:  24.9058501\n",
      "time taken: 0.0067014999999983615 minutes 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# Testing the extraction of MFCC & others using Librosa\n",
    "filename = 'train/1-3.wav'\n",
    "X, sample_rate = librosa.load(filename) \n",
    "start = timer()#####TONY\n",
    "mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "end = timer()#######TONY\n",
    "print(\"start: \", start)\n",
    "print(\"end: \", end)\n",
    "print(\"time taken: {0} minutes {1:.1f} seconds\".format((end - start), (end - start)%60))#######TONY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature extraction & Spec Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting MFCC\n",
    "def extract_features(file_name):\n",
    "    try:\n",
    "    \n",
    "   \n",
    "        X, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) #40######\n",
    "        mfcc_delta = librosa.feature.delta(mfccs) #TONY\n",
    "        mfcc_delta2 = librosa.feature.delta(mfccs, order=2)#TONY\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "        ###### ADD NEW FEATURES (SPECTRAL RELATED)##### 24-SEP\n",
    "        cent = np.mean(librosa.feature.spectral_centroid(y=X, sr=sample_rate).T,axis=0)\n",
    "        flatness = np.mean(librosa.feature.spectral_flatness(y=X).T,axis=0)\n",
    "        rolloff = np.mean(librosa.feature.spectral_rolloff(S=stft, sr=sample_rate).T,axis=0)\n",
    "        rms = np.mean(librosa.feature.rms(S=stft).T,axis=0)\n",
    "        ext_features = np.hstack([mfccs,mfcc_delta, mfcc_delta2, chroma, mel, contrast, tonnetz, cent,flatness, rolloff,rms])\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return np.array(ext_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start:  24.8991486\n",
      "end:  27.6418134\n",
      "time taken: 2.7426648 minutes 2.7 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(277,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFile='train/1-3.wav'\n",
    "testF = extract_features(testFile)\n",
    "end = timer()#######TONY\n",
    "print(\"start: \", start)\n",
    "print(\"end: \", end)\n",
    "print(\"time taken: {0} minutes {1:.1f} seconds\".format((end - start), (end - start)%60))#######TONY\n",
    "testF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Spectrogram Features\n",
    "def extract_features_spec(file_name):\n",
    "   \n",
    "    try:\n",
    "        X, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "        \n",
    "        mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "        ext_features = mel\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return np.array(ext_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFile = 'train/1-3.wav'\n",
    "testF2 = extract_features_spec(testFile)\n",
    "testF2.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Leo\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Leo\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Leo\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Leo\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Leo\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Leo\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Leo\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Leo\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Leo\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Leo\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Leo\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Leo\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "def create_mlp():    \n",
    "    # Construct model \n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(277,)))    ### 256\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Audio Features: Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_csv('train.csv',dtype=str)\n",
    "trainAudioPath = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Extracting Features...\n",
      "Finished feature extraction from  560 files\n"
     ]
    }
   ],
   "source": [
    "# MFCCs Features\n",
    "# Metadata file & full UrbanSound dataset \n",
    "train_features = []\n",
    "print(\"[INFO] Extracting Features...\")\n",
    "for fileID in traindf[\"ID\"]:\n",
    "    audioFile = fileID + '.wav'\n",
    "    audioDir = trainAudioPath + audioFile\n",
    "    data = extract_features(audioDir)\n",
    "    features.append(data)  \n",
    "print('Finished feature extraction from ', len(features), 'files') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The array is saved in the .npy file\n"
     ]
    }
   ],
   "source": [
    "np.save('trainAudioFeature277-111', features) \n",
    "print(\"The array is saved in the .npy file\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Auido Features: Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv('test.csv', dtype=str)\n",
    "testAudioPath = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Extracting Features...\n",
      "Finished feature extraction from  120 files\n"
     ]
    }
   ],
   "source": [
    "# MFCCs Features\n",
    "# Metadata file & full UrbanSound dataset \n",
    "\n",
    "test_features = []\n",
    "print(\"[INFO] Extracting Features...\")\n",
    "for fileID in testdf[\"ID\"]:\n",
    "    audioFile = fileID + '.wav'\n",
    "    audioDir = testAudioPath + audioFile\n",
    "    #print(audioPath)\n",
    "    data = extract_features(audioDir)\n",
    "    test_features.append(data)\n",
    "    \n",
    "print('Finished feature extraction from ', len(test_features), 'files') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The array is saved in the .npy file\n"
     ]
    }
   ],
   "source": [
    "# Save to binary file\n",
    "\n",
    "np.save('testAudioFeature277-222', test_features) \n",
    "print(\"The array is saved in the .npy file\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Audio Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAudioFeatures = np.load('trainAudioFeature277.npy', allow_pickle=True)\n",
    "testAudioFeatures = np.load('testAudioFeature277.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAudioFeatures = np.array(trainAudioFeatures)\n",
    "testAudioFeatures = np.array(testAudioFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk \n",
    "scaler1 = sk.preprocessing.StandardScaler().fit(trainAudioFeatures)\n",
    "trainAudioFeatures = scaler1.transform(trainAudioFeatures)\n",
    "testAudioFeatures = scaler1.transform(testAudioFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.utils.np_utils import to_categorical\n",
    "# LABELS\n",
    "train_labels = traindf[\"Class\"]\n",
    "test_labels = testdf[\"Class\"]\n",
    "#labels = to_categorical(labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(train_labels)\n",
    "train_labels = le.transform(train_labels)\n",
    "test_labels = le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 9, 3, 5, 6, 0, 1, 4, 7, 2, 0, 7, 6, 6, 0, 9, 3, 7, 1, 5, 8,\n",
       "       7, 6, 5, 8, 2, 1, 4, 6, 4, 5, 8, 2, 9, 1, 3, 4, 4, 2, 2, 8, 2, 8,\n",
       "       3, 7, 7, 1, 7, 7, 2, 8, 5, 6, 6, 2, 7, 0, 8, 1, 5, 6, 5, 5, 5, 0,\n",
       "       6, 7, 3, 6, 2, 0, 9, 3, 8, 2, 0, 8, 6, 7, 5, 2, 5, 4, 0, 0, 1, 1,\n",
       "       9, 5, 9, 0, 4, 4, 3, 8, 7, 3, 4, 6, 5, 2, 6, 1, 9, 6, 3, 6, 4, 7,\n",
       "       5, 1, 1, 9, 2, 9, 9, 9, 2, 1, 8, 1, 2, 4, 2, 3, 3, 1, 6, 5, 9, 0,\n",
       "       7, 1, 0, 2, 4, 9, 7, 7, 9, 1, 8, 1, 4, 9, 0, 1, 2, 7, 3, 8, 2, 2,\n",
       "       3, 1, 0, 4, 1, 3, 7, 3, 1, 9, 8, 4, 8, 0, 3, 0, 3, 4, 4, 5, 5, 3,\n",
       "       4, 6, 2, 0, 5, 5, 6, 1, 8, 3, 3, 7, 8, 9, 9, 6, 7, 0, 8, 7, 1, 6,\n",
       "       0, 1, 6, 8, 0, 0, 8, 2, 6, 4, 4, 8, 9, 1, 2, 8, 3, 5, 3, 4, 7, 9,\n",
       "       0, 7, 4, 3, 4, 4, 8, 0, 5, 7, 8, 2, 4, 5, 7, 1, 7, 1, 9, 2, 2, 9,\n",
       "       2, 9, 5, 6, 8, 6, 3, 5, 3, 2, 5, 3, 9, 6, 7, 9, 9, 5, 0, 9, 1, 0,\n",
       "       6, 6, 7, 6, 0, 5, 0, 3, 8, 4, 4, 8, 4, 8, 0, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training MLP (1-D Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading data...\n",
      "[INFO] processing data...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import concatenate\n",
    "import numpy as np\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "print(\"[INFO] loading data...\")\n",
    "#features, images, labels = features, images, labels\n",
    "\n",
    "print(\"[INFO] processing data...\")\n",
    "#split = train_test_split(features, images, labels, test_size=0.25, random_state=42)\n",
    "#(trainFeatureX, testFeatureX, trainImagesX, testImagesX, trainY, testY) = split\n",
    "\n",
    "\n",
    "trainFeatureX, testFeatureX, trainY, testY = trainAudioFeatures, testAudioFeatures, train_labels, test_labels\n",
    "\n",
    "# For prediction and Confusion Matrix\n",
    "trueY = testY\n",
    "\n",
    "trainY = to_categorical(trainY, 10)\n",
    "testY = to_categorical(testY, 10)\n",
    "\n",
    "\n",
    "# create the MLP and CNN models\n",
    "mlp = create_mlp()\n",
    "#cnn = create_cnn(64, 64, 3)\n",
    "\n",
    "# create the input to our final set of layers as the *output* of both the MLP and CNN\n",
    "#combinedInput = concatenate([mlp.output, cnn.output])\n",
    "\n",
    "Input = mlp.output\n",
    "\n",
    "# The final FC layer head will have two dense layers, the final one being softmax layer\n",
    "x = Dense(512, activation=\"relu\")(Input)\n",
    "x = Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "# The final model will accept audio on the MLP input and SPEC on the CNN input, outputting prediction\n",
    "model = Model(inputs=mlp.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 277)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeatureX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.02823775,  0.09519797,  0.72042677, ..., -0.1762181 ,\n",
       "        -0.05608618, -0.72162112],\n",
       "       [-0.70808832, -0.54849382, -1.1493005 , ..., -0.1743264 ,\n",
       "         1.3426475 , -0.23376805],\n",
       "       [-0.01900483,  1.12506077,  0.0637808 , ..., -0.17594879,\n",
       "        -0.1873744 , -0.79054427],\n",
       "       ...,\n",
       "       [ 0.89016453,  1.32402243, -1.28461814, ..., -0.16836045,\n",
       "         0.87325052,  0.96106802],\n",
       "       [ 0.406394  , -1.02565322,  0.51445425, ..., -0.11388191,\n",
       "         0.63058292, -0.13294628],\n",
       "       [ 0.4693118 ,  0.64976905,  0.08967686, ..., -0.17439502,\n",
       "        -1.07760843,  0.01542751]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeatureX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "Train on 280 samples, validate on 120 samples\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "GPU sync failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: GPU sync failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-dddf349074ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[INFO] training model...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainFeatureX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestFeatureX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2353\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2355\u001b[1;33m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m   2357\u001b[0m                               **self.session_kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    180\u001b[0m                 \u001b[1;31m# not already marked as initialized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m                 is_initialized = session.run(\n\u001b[1;32m--> 182\u001b[1;33m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[0;32m    183\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1368\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: GPU sync failed"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizers.rmsprop(lr=0.0005, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"]) #lr 0.0005\n",
    "\n",
    "# Train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(trainFeatureX, trainY, validation_data=(testFeatureX, testY), epochs=250, batch_size=32)  # 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Evaluating...\n",
      "960/960 [==============================] - 0s 33us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1585460499878915, 0.9770833333333333]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "print(\"[INFO] Evaluating...\")\n",
    "model.evaluate(testFeatureX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training CNN (1-D Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading data...\n",
      "[INFO] processing data...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 277, 512)          1024      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 277, 512)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 141824)            0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 141824)            0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1024)              145228800 \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 145,762,832\n",
      "Trainable params: 145,762,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(277, 1), filters=512, kernel_size=1)`\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import concatenate\n",
    "import numpy as np\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPool1D\n",
    "from keras import regularizers, optimizers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "print(\"[INFO] loading data...\")\n",
    "#features, images, labels = features, images, labels\n",
    "\n",
    "print(\"[INFO] processing data...\")\n",
    "#split = train_test_split(features, images, labels, test_size=0.25, random_state=42)\n",
    "#(trainFeatureX, testFeatureX, trainImagesX, testImagesX, trainY, testY) = split\n",
    "\n",
    "\n",
    "trainFeatureX, testFeatureX, trainY, testY = trainAudioFeatures, testAudioFeatures, train_labels, test_labels\n",
    "\n",
    "# For prediction and Confusion Matrix\n",
    "trueY = testY\n",
    "\n",
    "trainY = to_categorical(trainY, 16)\n",
    "testY = to_categorical(testY, 16)\n",
    "\n",
    "\n",
    "# define model\n",
    "n_steps = 1\n",
    "n_features = 277\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(filters=64, kernel_size=1, activation='relu', input_shape=(n_steps, n_features)))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(50, activation='relu'))\n",
    "# model.add(Dense(16,activation=\"softmax\"))\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(nb_filter=512, filter_length=1, input_shape=(n_features, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# # create the MLP and CNN models\n",
    "# #mlp = create_mlp()\n",
    "# cnn = create_cnn(120, 1, 1)\n",
    "\n",
    "# # create the input to our final set of layers as the *output* of both the MLP and CNN\n",
    "# #combinedInput = concatenate([mlp.output, cnn.output])\n",
    "\n",
    "# Input = cnn.output\n",
    "\n",
    "# # The final FC layer head will have two dense layers, the final one being softmax layer\n",
    "# x = Dense(512, activation=\"relu\")(Input)\n",
    "# x = Dense(16, activation=\"softmax\")(x)\n",
    "\n",
    "# # The final model will accept audio on the MLP input and SPEC on the CNN input, outputting prediction\n",
    "# model_cnn = Model(inputs=cnn.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "Train on 2112 samples, validate on 960 samples\n",
      "Epoch 1/250\n",
      "2112/2112 [==============================] - 7s 3ms/step - loss: 1.6011 - acc: 0.6089 - val_loss: 0.9298 - val_acc: 0.7010\n",
      "Epoch 2/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.5094 - acc: 0.8400 - val_loss: 0.3673 - val_acc: 0.8906\n",
      "Epoch 3/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.3411 - acc: 0.9119 - val_loss: 0.2864 - val_acc: 0.9052\n",
      "Epoch 4/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.2183 - acc: 0.9394 - val_loss: 0.2671 - val_acc: 0.9344\n",
      "Epoch 5/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.1968 - acc: 0.9455 - val_loss: 0.2143 - val_acc: 0.9490\n",
      "Epoch 6/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.1262 - acc: 0.9692 - val_loss: 0.1926 - val_acc: 0.9458\n",
      "Epoch 7/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.1083 - acc: 0.9749 - val_loss: 0.1654 - val_acc: 0.9563\n",
      "Epoch 8/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.1028 - acc: 0.9768 - val_loss: 0.1330 - val_acc: 0.9573\n",
      "Epoch 9/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0715 - acc: 0.9863 - val_loss: 0.3052 - val_acc: 0.9302\n",
      "Epoch 10/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0692 - acc: 0.9882 - val_loss: 0.1855 - val_acc: 0.9583\n",
      "Epoch 11/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0813 - acc: 0.9877 - val_loss: 0.1584 - val_acc: 0.9677\n",
      "Epoch 12/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0551 - acc: 0.9920 - val_loss: 0.2024 - val_acc: 0.9604\n",
      "Epoch 13/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0577 - acc: 0.9905 - val_loss: 0.2312 - val_acc: 0.9469\n",
      "Epoch 14/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0503 - acc: 0.9915 - val_loss: 0.1602 - val_acc: 0.9646\n",
      "Epoch 15/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0500 - acc: 0.9929 - val_loss: 0.2096 - val_acc: 0.9604\n",
      "Epoch 16/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0644 - acc: 0.9905 - val_loss: 0.2167 - val_acc: 0.9500\n",
      "Epoch 17/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0535 - acc: 0.9948 - val_loss: 0.2519 - val_acc: 0.9542\n",
      "Epoch 18/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0516 - acc: 0.9948 - val_loss: 0.2528 - val_acc: 0.9604\n",
      "Epoch 19/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0492 - acc: 0.9929 - val_loss: 0.1814 - val_acc: 0.9667\n",
      "Epoch 20/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0503 - acc: 0.9948 - val_loss: 0.1468 - val_acc: 0.9677\n",
      "Epoch 21/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0423 - acc: 0.9943 - val_loss: 0.1136 - val_acc: 0.9771\n",
      "Epoch 22/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0702 - acc: 0.9910 - val_loss: 0.1497 - val_acc: 0.9698\n",
      "Epoch 23/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0390 - acc: 0.9943 - val_loss: 0.3552 - val_acc: 0.9490\n",
      "Epoch 24/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0446 - acc: 0.9953 - val_loss: 0.2046 - val_acc: 0.9708\n",
      "Epoch 25/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0343 - acc: 0.9967 - val_loss: 0.1881 - val_acc: 0.9677\n",
      "Epoch 26/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0466 - acc: 0.9962 - val_loss: 0.2065 - val_acc: 0.9646\n",
      "Epoch 27/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0459 - acc: 0.9934 - val_loss: 0.2965 - val_acc: 0.9490\n",
      "Epoch 28/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0415 - acc: 0.9953 - val_loss: 0.2996 - val_acc: 0.9573\n",
      "Epoch 29/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0389 - acc: 0.9967 - val_loss: 0.2033 - val_acc: 0.9635\n",
      "Epoch 30/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0349 - acc: 0.9967 - val_loss: 0.1918 - val_acc: 0.9719\n",
      "Epoch 31/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0391 - acc: 0.9967 - val_loss: 0.1990 - val_acc: 0.9698\n",
      "Epoch 32/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0378 - acc: 0.9957 - val_loss: 0.1967 - val_acc: 0.9698\n",
      "Epoch 33/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0307 - acc: 0.9981 - val_loss: 0.2077 - val_acc: 0.9750\n",
      "Epoch 34/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0488 - acc: 0.9953 - val_loss: 0.2295 - val_acc: 0.9688\n",
      "Epoch 35/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0340 - acc: 0.9976 - val_loss: 0.3831 - val_acc: 0.9510\n",
      "Epoch 36/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0360 - acc: 0.9967 - val_loss: 0.2699 - val_acc: 0.9667\n",
      "Epoch 37/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0328 - acc: 0.9976 - val_loss: 0.2221 - val_acc: 0.9698\n",
      "Epoch 38/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0421 - acc: 0.9962 - val_loss: 0.2133 - val_acc: 0.9719\n",
      "Epoch 39/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2129 - val_acc: 0.9719\n",
      "Epoch 40/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2136 - val_acc: 0.9740\n",
      "Epoch 41/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0437 - acc: 0.9972 - val_loss: 0.2612 - val_acc: 0.9708\n",
      "Epoch 42/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0471 - acc: 0.9962 - val_loss: 0.2036 - val_acc: 0.9771\n",
      "Epoch 43/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2160 - val_acc: 0.9750\n",
      "Epoch 44/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2213 - val_acc: 0.9719\n",
      "Epoch 45/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2226 - val_acc: 0.9719\n",
      "Epoch 46/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2276 - val_acc: 0.9729\n",
      "Epoch 47/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2319 - val_acc: 0.9740\n",
      "Epoch 48/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2319 - val_acc: 0.9740\n",
      "Epoch 49/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2400 - val_acc: 0.9729\n",
      "Epoch 50/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0310 - acc: 0.9976 - val_loss: 0.2595 - val_acc: 0.9688\n",
      "Epoch 51/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0331 - acc: 0.9976 - val_loss: 0.2379 - val_acc: 0.9719\n",
      "Epoch 52/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2536 - val_acc: 0.9708\n",
      "Epoch 53/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2554 - val_acc: 0.9688\n",
      "Epoch 54/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2303 - val_acc: 0.9729\n",
      "Epoch 55/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2569 - val_acc: 0.9729\n",
      "Epoch 56/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2520 - val_acc: 0.9729\n",
      "Epoch 57/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2508 - val_acc: 0.9740\n",
      "Epoch 58/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2426 - val_acc: 0.9750\n",
      "Epoch 59/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2426 - val_acc: 0.9750\n",
      "Epoch 60/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2426 - val_acc: 0.9750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2426 - val_acc: 0.9750\n",
      "Epoch 62/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2426 - val_acc: 0.9750\n",
      "Epoch 63/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2387 - val_acc: 0.9740\n",
      "Epoch 64/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2387 - val_acc: 0.9740\n",
      "Epoch 65/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2387 - val_acc: 0.9740\n",
      "Epoch 66/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2387 - val_acc: 0.9740\n",
      "Epoch 67/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2387 - val_acc: 0.9740\n",
      "Epoch 68/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2387 - val_acc: 0.9740\n",
      "Epoch 69/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2387 - val_acc: 0.9740\n",
      "Epoch 70/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2402 - val_acc: 0.9750\n",
      "Epoch 71/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2402 - val_acc: 0.9750\n",
      "Epoch 72/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2402 - val_acc: 0.9750\n",
      "Epoch 73/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2402 - val_acc: 0.9750\n",
      "Epoch 74/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2402 - val_acc: 0.9750\n",
      "Epoch 75/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2402 - val_acc: 0.9750\n",
      "Epoch 76/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2402 - val_acc: 0.9750\n",
      "Epoch 77/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2402 - val_acc: 0.9750\n",
      "Epoch 78/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2414 - val_acc: 0.9729\n",
      "Epoch 79/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2414 - val_acc: 0.9729\n",
      "Epoch 80/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2414 - val_acc: 0.9729\n",
      "Epoch 81/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2402 - val_acc: 0.9740\n",
      "Epoch 82/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2402 - val_acc: 0.9740\n",
      "Epoch 83/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 84/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 85/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 86/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 87/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 88/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 89/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 90/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 91/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 92/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 93/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 94/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 95/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 96/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 97/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 98/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 99/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 100/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 101/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 102/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 103/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 104/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 105/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 106/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 107/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 108/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 109/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 110/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 111/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 112/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 113/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2408 - val_acc: 0.9740\n",
      "Epoch 114/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2382 - val_acc: 0.9729\n",
      "Epoch 115/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2382 - val_acc: 0.9729\n",
      "Epoch 116/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2382 - val_acc: 0.9729\n",
      "Epoch 117/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2382 - val_acc: 0.9729\n",
      "Epoch 118/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2382 - val_acc: 0.9729\n",
      "Epoch 119/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2382 - val_acc: 0.9729\n",
      "Epoch 120/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2382 - val_acc: 0.9729\n",
      "Epoch 121/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 122/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 123/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 124/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 125/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 126/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 127/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 128/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 129/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 130/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 131/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 132/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 133/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 134/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 135/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 136/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 137/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 138/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 139/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 140/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 141/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 142/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 143/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 144/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 145/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 146/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 147/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 148/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 149/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 150/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 151/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 152/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 153/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 154/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 155/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 156/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 157/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 158/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 159/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 160/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 161/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 162/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 163/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 164/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 165/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 166/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 167/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 168/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 169/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 170/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 171/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 172/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 173/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 174/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 175/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 176/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 177/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 178/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 179/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 180/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 182/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 183/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 184/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 185/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 186/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 187/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 188/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 189/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 190/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 191/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 192/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 193/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 194/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 195/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 196/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 197/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 198/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 199/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 200/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 201/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 202/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 203/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 204/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 205/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 206/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 207/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 208/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 209/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 210/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 211/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 212/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 213/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 214/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 215/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 216/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 217/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 218/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 219/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 220/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 221/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2441 - val_acc: 0.9740\n",
      "Epoch 222/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 223/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 224/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 225/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 226/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 227/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 228/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 229/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 230/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 231/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 232/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 233/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 234/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 235/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 236/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 237/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 238/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 239/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 240/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 242/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 243/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 244/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 245/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 246/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 247/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 248/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 249/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n",
      "Epoch 250/250\n",
      "2112/2112 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9981 - val_loss: 0.2440 - val_acc: 0.9740\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizers.rmsprop(lr=0.0005, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"]) #lr 0.0005\n",
    "\n",
    "# Train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(trainFeatureX.reshape(2112, 277,1), trainY, validation_data=(testFeatureX.reshape(960, 277,1), testY), epochs=250, batch_size=32)  # 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8925263570212446872\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6622735237\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17406887731317095264\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"99\"\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Evaluating...\n",
      "960/960 [==============================] - 0s 138us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24400023853540442, 0.9739583333333334]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "print(\"[INFO] Evaluating...\")\n",
    "model.evaluate(testFeatureX.reshape(960,277,1), testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN (1-D Feature: Mel-Spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction: Mean of Mel-Spec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Extracting Features...\n",
      "Finished feature extraction from  2112 files\n",
      "The array is saved in the .npy file\n"
     ]
    }
   ],
   "source": [
    "traindf = pd.read_csv('train.csv',dtype=str)\n",
    "trainAudioPath = \"ALL_A_TRAIN/\"\n",
    "\n",
    "mel_features = []\n",
    "print(\"[INFO] Extracting Features...\")\n",
    "for fileID in traindf[\"ID\"]:\n",
    "    audioFile = fileID + '.wav'\n",
    "    audioDir = trainAudioPath + audioFile\n",
    "    #print(audioPath)\n",
    "    data = extract_features_spec(audioDir)\n",
    "    mel_features.append(data)\n",
    "    \n",
    "print('Finished feature extraction from ', len(mel_features), 'files') \n",
    "\n",
    "# Save to binary file\n",
    "np.save('trainMelFeature', mel_features) \n",
    "print(\"The array is saved in the .npy file\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Extracting Features...\n",
      "Finished feature extraction from  960 files\n",
      "The array is saved in the .npy file\n"
     ]
    }
   ],
   "source": [
    "testdf = pd.read_csv('test.csv',dtype=str)\n",
    "trainAudioPath = \"ALL_A_TEST/\"\n",
    "\n",
    "mel2_features = []\n",
    "print(\"[INFO] Extracting Features...\")\n",
    "for fileID in testdf[\"ID\"]:\n",
    "    audioFile = fileID + '.wav'\n",
    "    audioDir = trainAudioPath + audioFile\n",
    "    #print(audioPath)\n",
    "    data = extract_features_spec(audioDir)\n",
    "    mel2_features.append(data)\n",
    "    \n",
    "print('Finished feature extraction from ', len(mel2_features), 'files') \n",
    "\n",
    "# Save to binary file\n",
    "np.save('testMelFeature', mel2_features) \n",
    "print(\"The array is saved in the .npy file\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk \n",
    "\n",
    "trainMelFeatures = np.load('trainMelFeature.npy', allow_pickle=True)\n",
    "testMelFeatures = np.load('testMelFeature.npy', allow_pickle=True)\n",
    "\n",
    "trainMelFeatures = np.array(trainMelFeatures)\n",
    "testMelFeatures = np.array(testMelFeatures)\n",
    "\n",
    "scaler1 = sk.preprocessing.StandardScaler().fit(trainMelFeatures)\n",
    "trainMelFeatures = scaler1.transform(trainMelFeatures)\n",
    "testMelFeatures = scaler1.transform(testMelFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 128)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainMelFeatures.shape\n",
    "testMelFeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "train_labels = traindf[\"Class\"]\n",
    "test_labels = testdf[\"Class\"]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels = le.transform(train_labels)\n",
    "test_labels = le.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading data...\n",
      "[INFO] processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:39: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(128, 1), filters=512, kernel_size=1)`\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import concatenate\n",
    "import numpy as np\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPool1D\n",
    "from keras import regularizers, optimizers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "print(\"[INFO] loading data...\")\n",
    "#features, images, labels = features, images, labels\n",
    "\n",
    "print(\"[INFO] processing data...\")\n",
    "#split = train_test_split(features, images, labels, test_size=0.25, random_state=42)\n",
    "#(trainFeatureX, testFeatureX, trainImagesX, testImagesX, trainY, testY) = split\n",
    "\n",
    "\n",
    "trainFeatureX, testFeatureX, trainY, testY = trainMelFeatures, testMelFeatures, train_labels, test_labels\n",
    "\n",
    "# For prediction and Confusion Matrix\n",
    "trueY = testY\n",
    "\n",
    "trainY = to_categorical(trainY, 16)\n",
    "testY = to_categorical(testY, 16)\n",
    "\n",
    "\n",
    "# define model\n",
    "n_steps = 1\n",
    "n_features = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(nb_filter=512, filter_length=1, input_shape=(n_features, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-96a7c506ee86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Compile the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmsprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#lr 0.0005\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[INFO] training model...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizers.rmsprop(lr=0.0005, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"]) #lr 0.0005\n",
    "\n",
    "# Train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(trainFeatureX.reshape(2112, 128,1), trainY, validation_data=(testFeatureX.reshape(960, 128,1), testY), epochs=250, batch_size=32)  # 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Evaluating...\n",
      "960/960 [==============================] - 0s 125us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1914734919865926, 0.796875]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "print(\"[INFO] Evaluating...\")\n",
    "model.evaluate(testFeatureX.reshape(960, 128,1), testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras_applications' has no attribute 'set_keras_submodules'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-98cd3281928c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_applications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m keras_applications.set_keras_submodules(\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras_applications' has no attribute 'set_keras_submodules'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
